<!doctype html>
<html lang="en" class="no-js">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-138188246-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-138188246-1');
    </script>

    <meta content="IE=edge" http-equiv="X-UA-Compatible">
    <meta charset="utf-8">
    <meta content="width=device-width,initial-scale=1.0,minimum-scale=1.0,maximum-scale=1.0,user-scalable=no" name="viewport">
      <meta name="robots" content="noindex">

    <title>Archive | Cloud Platform User Guide</title>

    <!--[if gt IE 8]><!--><link href="/stylesheets/screen.css" rel="stylesheet" media="screen" /><!--<![endif]-->
    <!--[if lte IE 8]><link href="/stylesheets/screen-old-ie.css" rel="stylesheet" media="screen" /><![endif]-->

    <link rel="canonical" href="https://user-guide.cloud-platform.service.justice.gov.uk/archive.html">


    <link href="/stylesheets/print.css" rel="stylesheet" media="print" />
    <script src="/javascripts/application.js"></script>

      <meta property="og:image" content="https://user-guide.cloud-platform.service.justice.gov.uk/images/govuk-large.png" />
      <meta property="og:site_name" content="Cloud Platform User Guide" />
      <meta property="og:title" content="Archive" />
      <meta property="og:type" content="object" />
      <meta property="og:url" content="https://user-guide.cloud-platform.service.justice.gov.uk/archive.html" />
      <meta property="twitter:card" content="summary" />
      <meta property="twitter:domain" content="user-guide.cloud-platform.service.justice.gov.uk" />
      <meta property="twitter:image" content="https://user-guide.cloud-platform.service.justice.gov.uk/images/govuk-large.png" />
      <meta property="twitter:title" content="Archive | Cloud Platform User Guide" />
      <meta property="twitter:url" content="https://user-guide.cloud-platform.service.justice.gov.uk/archive.html" />

    
  </head>

  <body>
    <div class="app-pane">
      <div class="app-pane__header toc-open-disabled">
        <a href="#content" class="skip-link">Skip to main content</a>

        <header class="header header--full-width">
  <div class="header__container">
    <div class="header__brand">
        <a href="/">
        <span class="header__title">
          Cloud Platform User Guide
            <span class="phase-banner">INTERNAL</span>
        </span>
        </a>
    </div>

      <div data-module="navigation">
        <button type="button" class="header__navigation-toggle js-nav-toggle" aria-controls="navigation" aria-label="Show or hide top level navigation">Menu</button>

        <nav id="navigation" class="header__navigation js-nav" aria-label="Top Level Navigation" aria-hidden="true">
          <ul>
              <li>
                <a href="mailto:platforms+user-guide@digital.justice.gov.uk?subject=User+guide+feedback">Feedback / Report a problem</a>
              </li>
              <li>
                <a href="/">Documentation</a>
              </li>
              <li>
                <a href="https://github.com/ministryofjustice/cloud-platform-user-guide">GitHub</a>
              </li>
          </ul>
        </nav>
      </div>
  </div>
</header>

      </div>

        <div id="toc-heading" class="toc-show fixedsticky">
          <a href="#toc" class="toc-show__label js-toc-show" aria-controls="toc">
            Table of contents <span class="toc-show__icon"></span>
          </a>
        </div>

      <div class="app-pane__body" data-module="in-page-navigation">
          <div class="app-pane__toc">
            <div class="toc" data-module="table-of-contents">
              <div class="search" data-module="search">
  <form action="https://www.google.co.uk/search" method="get" role="search">
    <input type="hidden" name="as_sitesearch" value="https://user-guide.cloud-platform.service.justice.gov.uk"/>
    <label for="search"  class="search__label">Search (via Google)</label>
    <input type="text" id="search" name="q" placeholder="Search" aria-controls="search-results" class="form-control" />
  </form>
  <div id="search-results" class="search-results" aria-hidden="true" role="dialog" aria-labelledby="search-results-title">
    <div class="search-results__inner">
      <button class="search-results__close">Close<span class="search-results__close-label"> search results</span></button>
      <h2 id="search-results-title" class="search-results__title" aria-live="polite">Results</h2>
      <div class="search-results__content"></div>
    </div>
  </div>
</div>

              <a href="#" class="toc__close js-toc-close" aria-controls="toc" aria-label="Hide table of contents"></a>
              <nav id="toc" class="js-toc-list toc__list" aria-labelledby="toc-heading" data-module="collapsible-navigation">
                      <ul>
  <li>
    <a href="/#cloud-platform-user-guide">Cloud platform user guide</a>
    <ul>
      <li>
        <ul>
          <li>
            <a href="/#this-guide">This guide</a>
          </li>
          <li>
            <a href="/#who-is-the-platform-for">Who is the platform for</a>
          </li>
          <li>
            <a href="/#what-do-we-currently-support">What do we currently support</a>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/concepts.html#concepts">Concepts</a>
    <ul>
      <li>
        <a href="/concepts.html#kubernetes">Kubernetes</a>
        <ul>
          <li>
            <a href="/concepts.html#resources">Resources</a>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/tasks.html#tasks">Tasks</a>
    <ul>
      <li>
        <a href="/tasks.html#how-to-use-kubectl-to-connect-to-the-cluster">How to use kubectl to connect to the cluster</a>
        <ul>
          <li>
            <a href="/tasks.html#installation">Installation</a>
          </li>
          <li>
            <a href="/tasks.html#authentication">Authentication</a>
          </li>
          <li>
            <a href="/tasks.html#where-to-go-from-here">Where to go from here?</a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/tasks.html#creating-a-cloud-platform-environment">Creating a Cloud Platform Environment</a>
        <ul>
          <li>
            <a href="/tasks.html#creating-a-cloud-platform-environment-introduction">Introduction</a>
          </li>
          <li>
            <a href="/tasks.html#creating-a-cloud-platform-environment-objective">Objective</a>
          </li>
          <li>
            <a href="/tasks.html#create-an-environment">Create an environment</a>
          </li>
          <li>
            <a href="/tasks.html#accessing-your-environments">Accessing your environments</a>
          </li>
          <li>
            <a href="/tasks.html#creating-a-cloud-platform-environment-next-steps">Next steps</a>
          </li>
          <li>
            <a href="/tasks.html#more-information-on-environment-definition">More information on environment definition</a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/tasks.html#creating-an-ecr-repository">Creating an ECR repository</a>
        <ul>
          <li>
            <a href="/tasks.html#creating-an-ecr-repository-introduction">Introduction</a>
          </li>
          <li>
            <a href="/tasks.html#accessing-the-credentials">Accessing the credentials</a>
          </li>
          <li>
            <a href="/tasks.html#creating-an-ecr-repository-next-steps">Next steps</a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/tasks.html#adding-aws-resources-to-your-environment">Adding AWS resources to your environment</a>
        <ul>
          <li>
            <a href="/tasks.html#available-modules">Available modules</a>
          </li>
          <li>
            <a href="/tasks.html#adding-aws-resources-to-your-environment-usage">Usage</a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/tasks.html#concepts-deploying-applications">Deploying Applications</a>
        <ul>
          <li>
            <a href="/tasks.html#deploying-a-39-hello-world-39-application-to-the-cloud-platform">Deploying a ‘Hello World’ application to the Cloud Platform</a>
          </li>
          <li>
            <a href="/tasks.html#deploying-a-multi-container-application-to-the-cloud-platform">Deploying a multi-container application to the Cloud Platform</a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/tasks.html#how-do-i-run-rails-database-migrations">How do I run Rails database migrations?</a>
        <ul>
          <li>
            <a href="/tasks.html#do-not-run-migrations-on-container-startup">Do not run migrations on container startup</a>
          </li>
          <li>
            <a href="/tasks.html#how-do-i-run-rails-database-migrations-further-reading">Further reading</a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/tasks.html#adding-a-secret-to-an-application">Adding a secret to an application</a>
        <ul>
          <li>
            <a href="/tasks.html#adding-a-secret-to-an-application-overview">Overview</a>
          </li>
          <li>
            <a href="/tasks.html#adding-a-secret-to-an-application-prerequisites">Prerequisites</a>
          </li>
          <li>
            <a href="/tasks.html#configuring-secrets">Configuring secrets</a>
          </li>
          <li>
            <a href="/tasks.html#creating-the-secret">Creating the secret</a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/tasks.html#concepts-cleaning-up">Cleaning up</a>
        <ul>
          <li>
            <a href="/tasks.html#concepts-cleaning-up-2-tell-terraform-to-delete-your-aws-resources">2. Tell terraform to delete your AWS resources</a>
          </li>
          <li>
            <a href="/tasks.html#concepts-cleaning-up-3-remove-your-namespace-code-from-the-cloud-platform-environments-repository">3. Remove your namespace code from the cloud-platform-environments repository</a>
          </li>
          <li>
            <a href="/tasks.html#concepts-cleaning-up-4-delete-all-of-the-kubernetes-resources-inside-your-namespace">4. Delete all of the kubernetes resources inside your namespace.</a>
          </li>
          <li>
            <a href="/tasks.html#concepts-cleaning-up-5-delete-your-namespace-from-the-cluster">5. Delete your namespace from the cluster.</a>
          </li>
          <li>
            <a href="/tasks.html#concepts-cleaning-up-summary">Summary</a>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/reference.html#reference">Reference</a>
    <ul>
      <li>
        <a href="/reference.html#kubernetes-resources">Kubernetes resources</a>
        <ul>
          <li>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/getting-help.html#getting-help">Getting Help</a>
    <ul>
      <li>
        <a href="/getting-help.html#slack-channel">Slack Channel</a>
      </li>
      <li>
        <a href="/getting-help.html#raise-a-support-ticket">Raise a support ticket</a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/archive.html#archive">Archive</a>
    <ul>
      <li>
        <a href="/archive.html#deploying-applications">Deploying Applications</a>
        <ul>
          <li>
            <a href="/archive.html#prerequisite-for-live-1-deployment">Prerequisite for Live-1 deployment</a>
          </li>
          <li>
            <a href="/archive.html#deploying-an-application-to-the-cloud-platform-with-helm">Deploying an application to the Cloud Platform with Helm</a>
          </li>
          <li>
            <a href="/archive.html#continuous-deployment-of-an-application-using-circleci-and-helm">Continuous Deployment of an application using CircleCI and Helm</a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/archive.html#cleaning-up">Cleaning up</a>
        <ul>
          <li>
            <a href="/archive.html#2-tell-terraform-to-delete-your-aws-resources">2. Tell terraform to delete your AWS resources</a>
          </li>
          <li>
            <a href="/archive.html#3-remove-your-namespace-code-from-the-cloud-platform-environments-repository">3. Remove your namespace code from the cloud-platform-environments repository</a>
          </li>
          <li>
            <a href="/archive.html#4-delete-all-of-the-kubernetes-resources-inside-your-namespace">4. Delete all of the kubernetes resources inside your namespace.</a>
          </li>
          <li>
            <a href="/archive.html#5-delete-your-namespace-from-the-cluster">5. Delete your namespace from the cluster.</a>
          </li>
          <li>
            <a href="/archive.html#summary">Summary</a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/archive.html#monitoring-applications">Monitoring Applications</a>
        <ul>
          <li>
            <a href="/archive.html#using-the-cloud-platform-prometheus-alertmanager-and-grafana">Using the Cloud Platform Prometheus, AlertManager and Grafana</a>
          </li>
          <li>
            <a href="/archive.html#creating-your-own-custom-alerts">Creating your own custom alerts</a>
          </li>
          <li>
            <a href="/archive.html#getting-application-metrics-into-prometheus">Getting Application Metrics into Prometheus</a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/archive.html#application-logging">Application Logging</a>
        <ul>
          <li>
            <a href="/archive.html#application-log-collection-and-storage">Application Log Collection and Storage</a>
          </li>
          <li>
            <a href="/archive.html#accessing-application-log-data">Accessing Application Log Data</a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/archive.html#other-topics">Other Topics</a>
        <ul>
          <li>
            <a href="/archive.html#git-crypt">Git-Crypt</a>
          </li>
          <li>
            <a href="/archive.html#secrets-overview">Secrets overview</a>
          </li>
          <li>
            <a href="/archive.html#kubectl-quick-reference">Kubectl quick reference</a>
          </li>
          <li>
            <a href="/archive.html#cloud-platform-support">Cloud Platform Support</a>
          </li>
          <li>
            <a href="/archive.html#zero-downtime-deployments">Zero Downtime Deployments</a>
          </li>
          <li>
            <a href="/archive.html#contributing-to-this-document">Contributing to this document</a>
          </li>
          <li>
            <a href="/archive.html#using-an-externally-managed-hostname">Using an externally-managed hostname</a>
          </li>
          <li>
            <a href="/archive.html#ip-whitelisting">IP Whitelisting</a>
          </li>
          <li>
            <a href="/archive.html#ecr-lifecycle-policy">ECR Lifecycle Policy</a>
          </li>
          <li>
            <a href="/archive.html#applying-a-maintenance-page">Applying a Maintenance Page</a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/archive.html#live-1-migration-guide">Live 1 Migration Guide</a>
        <ul>
          <li>
            <a href="/archive.html#live-1-migration-guide-overview">Overview</a>
          </li>
          <li>
            <a href="/archive.html#accessing-the-live-1-cluster">Accessing the Live-1 cluster</a>
          </li>
          <li>
            <a href="/archive.html#generating-a-new-environment">Generating a new environment</a>
          </li>
          <li>
            <a href="/archive.html#generating-a-new-ecr-repository">Generating a new ECR repository</a>
          </li>
          <li>
            <a href="/archive.html#changing-the-circleci-environment-variables">Changing the CircleCI environment variables</a>
          </li>
          <li>
            <a href="/archive.html#deleting-your-live-0-deployment">Deleting your Live-0 deployment</a>
          </li>
          <li>
            <a href="/archive.html#other-considerations">Other considerations</a>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>


              </nav>
            </div>
          </div>

        <div class="app-pane__content toc-open-disabled">
          <main id="content" class="technical-documentation" data-module="anchored-headings">
              <h1 id="archive">Archive</h1>
<h2 id="deploying-applications">Deploying Applications</h2>

<h3 id="prerequisite-for-live-1-deployment">Prerequisite for Live-1 deployment</h3><p><strong>This section only applies to applications aiming to be deployed to Live-1.</strong></p>
<p>In Live-1, the Cloud Platform team introduced <a href="https://kubernetes.io/docs/concepts/policy/pod-security-policy/">Pod Security Policies</a>, to
tighten the security on this production cluster.  Two policies have been
applied to the cluster, <em>restricted</em> and <em>privileged</em>.</p>
<p>By default, any new environment/namespace on Live-1 will be assigned the
<em>restricted</em> policy</p>
<h4 id="impact">Impact</h4><p>The main impact of this <em>restricted</em> policy is that it prevents pods/containers
from running as the root user. A container&rsquo;s user is usually defined in its
Dockerfile. If no user is explicitly specified in the Dockerfile, the chances
are that it will run as root.</p>
<p>It is important to understand that not being able to use root also implies that
it is impossible to bind to a privileged port (e.g. 80, 443).</p>
<p>The policies only take effect after the container has started. Anything in the
Dockerfile can be run as root at image build time e.g. to install required
software.</p>
<h4 id="how-to-adapt-to-the-pod-security-policies">How to adapt to the pod security policies</h4><p>Most of the time, your application&rsquo;s Dockerfile can be easily adapted by:</p>

<ul>
<li><p>Creating a user with a UID which is greater than 1 (which is the UID
reserved for root)</p></li>
<li><p>Giving this user any required permissions to access the files/directories
the application requires.</p></li>
<li><p>Adding a <code>USER</code> clause in your Dockerfile to switch to your non-root user</p></li>
</ul>
<p>Example:</p>
<div class="highlight"><pre class="highlight yaml"><code><span class="s">FROM busybox</span>

<span class="s">RUN mkdir -p /opt/myFolder &amp;&amp; \</span>
    <span class="s">adduser --disabled-password myNewUser -u 1001 &amp;&amp; \</span>
    <span class="s">chown -R myNewUser:myNewUser /opt/myFolder</span>

<span class="s">USER 1001</span>

<span class="s">CMD myApplication</span>
</code></pre></div><p>Depending on the base image, you might also need to explicitly create a group
for the user. In the busybox example above, a &lsquo;myNewUser&rsquo; group is implicitly
created by the adduser command.</p>
<p><strong>You must specify the user by its numeric UID</strong>, as above, not by its
username.  If you use the username (<code>USER myNewUser</code>) then the pod security
policy will not be able to tell that that is a non-root user, and your
container will not be scheduled.</p>
<p>A more complete example can be found here :
<a href="https://github.com/ministryofjustice/cloud-platform-multi-container-demo-app/blob/master/rails-app/Dockerfile">Dockerfile</a></p>
<h5 id="adapting-the-nginx-image">Adapting the NGINX image</h5><p>Since NGINX binds itself to a privileged port by default, it will not be able
to run as-is with the <em>restricted</em> policy.</p>
<p>The cloud-platform team will update this page with relevant documentation
regarding nginx, as soon as it is ready.  In the meantime, feel free to reach
out to the cloud-platform team for help : <a href="/getting-help.html">Getting Help</a></p>

<h3 id="deploying-an-application-to-the-cloud-platform-with-helm">Deploying an application to the Cloud Platform with Helm</h3><h4 id="introduction">Introduction</h4><p>This document will act as a guide to your first application deployment into the Cloud Platform. If you have any issues completing the objective or have any suggestions please feel free to drop use a line in the ##ask-cloud-platform slack channel.</p>
<h5 id="objective">Objective</h5><p>By the end of this guide you&rsquo;ll have deployed a reference <a href="https://github.com/ministryofjustice/cloud-platform-reference-app">Django application</a> to a cluster using the Kubernetes package manager <a href="https://helm.sh/">Helm</a>.</p>
<p><em>Disclaimer: You&rsquo;ll see fairly quickly that the application is not fit for production. A perfect example of this is the <a href="https://github.com/ministryofjustice/cloud-platform-reference-app/blob/master/helm_deploy/django-app/templates/secret.yaml">plaintext secrets file</a>. For the reference application we&rsquo;ve left this file in plaintext but it *</em>must** be encrypted when writing your own manifests for production/non-production work in the MoJ.*</p>
<h5 id="requirements">Requirements</h5><p>It is assumed you have the following:</p>

<ul>
<li>You have a basic understanding of what <a href="https://kubernetes.io/">Kubernetes</a> is.</li>
<li>You have <a href="/tasks.html#creating-a-cloud-platform-environment">created an environment for your application</a></li>
<li>You have installed <a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/">Kubectl</a> on your local machine.</li>
<li>You have <a href="/tasks.html#authentication">Authenticated</a> to the cloud-platform-live-1 cluster.</li>
</ul>
<h4 id="deploy-the-app">Deploy the app</h4><p>The reference application we&rsquo;re going to use is a very simple Django application with an on-cluster Postgresql database.</p>

<blockquote>
<p>Note: Even though we are going to install a database within the Kubernetes cluster, it is recommended to use a database as a service offering such as <a href="https://aws.amazon.com/rds/">AWS RDS</a> if running in production.</p>
</blockquote>
<p>The Helm deployment manifests have been pre-written for this exercise. But if you wish to know more about these files and what they do have a quick browse of the <a href="https://github.com/ministryofjustice/cloud-platform-reference-app/tree/master/helm_deploy/django-app/README.md">README</a>.</p>
<h5 id="set-up">Set up</h5><p>First we need to clone our reference application and change directory:</p>
<div class="highlight"><pre class="highlight plaintext"><code>$ git clone https://github.com/ministryofjustice/cloud-platform-reference-app.git
$ cd cloud-platform-reference-app
</code></pre></div><p>You now have a functioning git repository that contains a simple Django application. Have a browse around and get familiar with the directory structure.</p>
<h5 id="browse-the-cluster">Browse the cluster</h5><p>Let&rsquo;s make use of the command line tool <code>kubectl</code> to browse around the cluster to see what it looks like before we deploy our application:</p>
<div class="highlight"><pre class="highlight plaintext"><code>$ kubectl get pods --namespace &lt;env-name&gt;
</code></pre></div><p><em>The <code>&lt;env-name&gt;</code> here is the environment you created, listed in the requirements section at the beginning of the document.</em></p>
<p>If you receive the below error message then you&rsquo;ve either not typed in your namespace correctly or you don&rsquo;t have permission to perform a <code>get pods</code> command. Either way, you&rsquo;ll need to go back and review the <a href="/tasks.html#creating-a-cloud-platform-environment">Creating an Environment</a> document previously mentioned.</p>
<div class="highlight"><pre class="highlight plaintext"><code>$ Error from server (Forbidden): pods is forbidden: User "test-user" cannot list pods in the namespace "demo"
</code></pre></div><h5 id="using-helm">Using Helm</h5><p>Helm allows you to manage application deployment to Kubernetes using Charts. You can read about of some of the many features of <a href="https://docs.helm.sh/developing_charts/">Helm Charts</a>. We&rsquo;ve chosen to use Helm as the default way to deploy applications to the Cloud Platform as it provides useful tooling as an interface to the YAML files that Kubernetes uses to run.</p>
<h6 id="tiller-rbac-configuration">Tiller RBAC Configuration</h6><p>There are two parts to Helm: The client and the Helm server (Tiller).</p>
<p>We will create a <code>Service Account</code> resource by adding to your <code>01-rbac.yaml</code> file. This gives Helm the permissions it needs to deploy within your namespace.</p>
<p>Add the following to the bottom of the <code>01-rbac.yaml</code> file you defined when you <a href="/tasks.html#creating-a-cloud-platform-environment">created your environment</a>:</p>
<div class="highlight"><pre class="highlight plaintext"><code>---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: tiller
  namespace: myapp-dev ### Your namespace `&lt;servicename-env&gt;`
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: tiller
  namespace: myapp-dev ### Your namespace `&lt;servicename-env&gt;`
subjects:
- kind: ServiceAccount
  name: tiller
  namespace: myapp-dev ### Your namespace `&lt;servicename-env&gt;`
roleRef:
  kind: ClusterRole
  name: cluster-admin
  apiGroup: rbac.authorization.k8s.io
</code></pre></div><p>After you have added this to the file, commit it and create a pull request against the <a href="https://github.com/ministryofjustice/cloud-platform-environments">cloud-platform-environments</a> master repo.</p>
<p>Once it is merged and applied, you will have a service account for Tiller that allows it act on your namespace. Now you have to install Helm and Tiller into your namespace.</p>
<h6 id="installing-and-configuring-helm-and-tiller">Installing and configuring Helm and Tiller</h6><p>Install the client via Homebrew or by other <a href="https://docs.helm.sh/using_helm/###installing-helm">means</a>:</p>
<div class="highlight"><pre class="highlight plaintext"><code>$ brew install kubernetes-helm
</code></pre></div><p>Now configure the installation with Tiller:</p>
<div class="highlight"><pre class="highlight plaintext"><code>$ helm init --tiller-namespace &lt;env-name&gt; --service-account tiller
</code></pre></div><p>When succesful, you&rsquo;ll be greeted with the message:</p>
<div class="highlight"><pre class="highlight plaintext"><code>Happy Helming
</code></pre></div><p>This is an indication we&rsquo;re ready to deploy our applicaton.</p>
<h6 id="application-install">Application install</h6><p>To deploy the application with Helm first change directory so we can focus on the app we need:</p>
<div class="highlight"><pre class="highlight plaintext"><code>$ cd helm_deploy/django-app/
</code></pre></div><p>Values for our application are stored in the <code>values.yaml</code> at the root of our directory. Configurations such as &lsquo;number of pods running&rsquo; and which image repository to use is stored here in this file. Open this file and get familiar with our application layout.</p>
<p>There is an important value in this file called <code>host</code>, which sets the URL for your application. We have to provide this value as an argument on our installation command.</p>
<p>Run the following (replacing the <code>YourName</code> with your own name and <code>env-name</code> with your environment name:</p>
<div class="highlight"><pre class="highlight plaintext"><code>    $ helm install . \
      --name django-app-&lt;YourName&gt; \
      --namespace &lt;env-name&gt; \
      --set deploy.host=django-&lt;YourName&gt;.apps.live-1.cloud-platform.service.justice.gov.uk \
      --tiller-namespace &lt;env-name&gt;
</code></pre></div>
<blockquote>
<p>Note: We&rsquo;re naming it like this as app names and host names have to be unique on the cluster.</p>
</blockquote>
<p>The <code>set deploy.host</code> overwrites the value stored in my <code>value.yaml</code> file and you&rsquo;ll see a fairly verbose output showing your pods creating.</p>
<h5 id="viewing-your-application">Viewing your application</h5><p>Congratulations on getting this far. If all went well your pods are now deployed and is now being served on your specified URL.</p>
<p>Let&rsquo;s check:</p>
<div class="highlight"><pre class="highlight plaintext"><code>$ kubectl get pods --namespace &lt;env-name&gt;
</code></pre></div><p>If the deploy was successful you should be greeted with something similar to the below:</p>
<div class="highlight"><pre class="highlight plaintext"><code>NAME                                           READY     STATUS    RESTARTS   AGE
django-app-&lt;Name&gt;-fcc657679-w69cr               1/1       Running   1          39m
django-app-&lt;Name&gt;-fcc657679-c5wdm               1/1       Running   1          39m
django-app-&lt;Name&gt;-db-migration-dgnse-qgs7r      0/1       Completed 0          39m
django-app-&lt;Name&gt;-postgresql-7b4bdff4b8-xdlw2   1/1       Running   0          39m
</code></pre></div><p>You should have a postgres pod and 2 app pods <strong>ready</strong> with the status <strong>running</strong>.</p>
<p>(There&rsquo;s also a line for a pod which ran the initial database migrations, but that&rsquo;s completed and no longer running so we&rsquo;ll ignore it.)</p>
<p>Let&rsquo;s check your host has a URL by running:</p>
<div class="highlight"><pre class="highlight plaintext"><code>$ kubectl get ingress --namespace &lt;env-name&gt;
</code></pre></div><p>This will return the URL of your given app. Open it using your favourite browser.</p>
<p>You should be met with an MoJ reference app with the title, <em>&lsquo;Cloud Platforms Deployment&rsquo;</em>. As we mentioned before, there is nothing complicated about this application. You can enter your name and job role, calling the on-cluster postgresql database.</p>
<h5 id="view-the-logs">View the logs</h5><p>Each pod will generate logs that can be viewed via the API. Let&rsquo;s have a browse of our application logs.</p>
<p>First grab the pod name:</p>
<div class="highlight"><pre class="highlight plaintext"><code>$ kubectl get pods --namespace &lt;env-name&gt;
</code></pre></div><p>Then copy the name of a pod that isn&rsquo;t postgresql.</p>
<div class="highlight"><pre class="highlight plaintext"><code>   NAME                                           READY     STATUS    RESTARTS   AGE
 * django-app-&lt;name&gt;-fcc657679-w69cr               1/1       Running   1          54m
   django-app-&lt;name&gt;-fcc657679-c5wdm               1/1       Running   1          39m
   django-app-&lt;name&gt;-postgresql-7b4bdff4b8-xdlw2   1/1       Running   0          54m
</code></pre></div><p>We&rsquo;re going to follow the log, so we&rsquo;ll run:</p>
<div class="highlight"><pre class="highlight plaintext"><code>$ kubectl logs django-app-&lt;name&gt;-fcc657679-w69cr --namespace &lt;env-name&gt; -f
</code></pre></div><p>As you can see, this tails the log and you should see our health checks giving a HTTP 200.</p>
<p>Read more about Kubernetes logging <a href="https://kubernetes.io/docs/concepts/cluster-administration/logging/">here</a>.</p>
<h5 id="scale-the-application">Scale the application</h5><p>You now have our application up and running but you decide two pods aren&rsquo;t enough. Say you want to run three. This is simply a case of changing the replicaCount value in the values.yaml whilst running the <code>helm upgrade</code> command.</p>
<p>Let&rsquo;s try:</p>
<div class="highlight"><pre class="highlight plaintext"><code>$ helm upgrade django-app-&lt;YourName&gt; . --set replicaCount=3 --tiller-namespace &lt;env-name&gt; --set deploy.host=&lt;DeploymentURL&gt;
</code></pre></div><p>This command spins up another pod to bring the total number to 3.</p>
<p>If we run the familiar command we&rsquo;ve been using:</p>
<div class="highlight"><pre class="highlight plaintext"><code>$ kubectl get pods --namespace &lt;env-var&gt;
</code></pre></div><p>You&rsquo;ll see the pod replication in progress.</p>
<h5 id="tear-it-all-down">Tear it all down</h5><p>Finally, we have built are app and deployed to the cluster. There is only one thing left to do. Destroy it.</p>
<p>To delete the deployment you simply run:</p>
<div class="highlight"><pre class="highlight plaintext"><code>$ helm del --purge django-app-&lt;YourName&gt; --tiller-namespace &lt;env-name&gt;
</code></pre></div><p>And then confirm the pods are terminating as expected:</p>
<div class="highlight"><pre class="highlight plaintext"><code>$ kubectl get pods --namespace &lt;env-var&gt;
</code></pre></div><h4 id="next-steps">Next steps</h4><p>The next step will be to create your own Helm Chart. You can try this with an application of your own or run through <a href="https://docs.bitnami.com/kubernetes/how-to/create-your-first-helm-chart/">Bitnami&rsquo;s excellent guide</a> on how to build using a simple quickstart.</p>

<h3 id="continuous-deployment-of-an-application-using-circleci-and-helm">Continuous Deployment of an application using CircleCI and Helm</h3><h4 id="continuous-deployment-of-an-application-using-circleci-and-helm-introduction">Introduction</h4><p>This document covers how to continuously deploy your application in the Cloud Platform. It is essentially a continuation of <a href="/archive.html#deploying-an-application-to-the-cloud-platform-with-helm">‘Deploying an application to the Cloud Platform with Helm’</a>.</p>
<p><em>Note: This document is specific to using <a href="https://circleci.com/">CircleCI</a> as the Continuous Integration method.</em></p>
<h5 id="continuous-deployment-of-an-application-using-circleci-and-helm-introduction-objective">Objective</h5><p>By the end of the tutorial, you will have done the following:</p>

<ul>
<li>Created a Service Account for CircleCI in your namespace</li>
<li>Generated a CircleCI configuration file in your application repository. The configuration file will authenticate with your chosen cluster, build a docker image and push it to ECR and upgrade your helm deployment with the new docker image.</li>
<li>Have an automated CircleCI pipeline that upgrades your helm deployment when a new change is pushed to your master branch</li>
</ul>
<h5 id="continuous-deployment-of-an-application-using-circleci-and-helm-introduction-requirements">Requirements</h5><p>It is assumed you have the following:</p>

<ul>
<li>You have <a href="/getting-started/env-create">created an environment for your application</a></li>
<li>You have <a href="/archive.html#deploying-an-application-to-the-cloud-platform-with-helm">deployed an application</a> to the &lsquo;cloud-platform-live-1&rsquo; cluster using Helm.</li>
<li>You have created an <a href="/tasks.html#creating-an-ecr-repository">ECR repository</a></li>
</ul>
<h5 id="creating-a-service-account-for-circleci">Creating a Service Account for CircleCI</h5><p>As part of the CircleCI deployment pipeline, CircleCI will need to authenticate with the Kubernetes cluster. In order to do so, Kubernetes uses <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/">Service Accounts</a>. Service Accounts provide an identity for processes that run in a cluster allowing the process to access the API server.</p>
<p>A Service Account is created in the <a href="https://github.com/ministryofjustice/cloud-platform-environments/tree/master/namespaces">namespace creation github repository</a>.
&ldquo;`bash
  $ kubectl get serviceaccounts &ndash;namespace $ns
  NAME       SECRETS   AGE
  circleci   1         3h</p>
<p>$ kubectl get serviceaccounts/circleci &ndash;namespace reference-app -o yaml
  apiVersion: v1
  kind: ServiceAccount
  &hellip;
  secrets:
  - name: circleci-token-prlkp</p>
<p>$ kubectl get secrets &ndash;namespace $ns
  NAME                   TYPE                                  DATA      AGE
  circleci-token-prlkp   kubernetes.io/service-account-token   3         3h</p>
<p>$ kubectl get secrets/circleci-token-prlkp &ndash;namespace $ns -o yaml
  &hellip;
  namespace: cm..cA==
  token: ZX&hellip;EE=
&rdquo;`</p>
<h5 id="linking-repository-to-circleci">Linking Repository to CircleCI</h5><p>MoJ has as an account with CircleCI, please login to <a href="https://circleci.com/dashboard">CircleCI</a> using GitHub credentials. Select project, and if config.yml is in the repo CircleCI will build and run tests.</p>
<h5 id="add-variables-to-circleci">Add variables to CircleCI</h5><p>There is a number of environment variables that you will need to set on your CircleCI project in order to build a docker image, push it to the ECR and trigger a deployment in your environment. On the project page, click the cog icon in the top right corner and select <code>Enviroment Variables</code> under <code>Build Settings</code>. The variables you will need to set are listed below.</p>
<h6 id="aws-credentials">AWS credentials</h6><p>To authenticate with ECR, you will need to set:
- <code>AWS_DEFAULT_REGION</code> - would be <code>eu-west-2</code> for Cloud Platform clusters unless specified otherwise
- <code>AWS_ACCESS_KEY_ID</code>
- <code>AWS_SECRET_ACCESS_KEY</code>
- <code>ECR_ENDPOINT</code> is optional but useful if you want to avoid having to hardcode the full hostname of the registry</p>
<h6 id="kubernetes-serviceaccount-credentials">Kubernetes <code>ServiceAccount</code> credentials</h6><p>Since a single CircleCI project will need to access multiple namespaces in kubernetes (the environments), it will also need to handle multiple credentials. To simplify authentication, we provide a helper script in our supported <a href="https://github.com/ministryofjustice/cloud-platform-tools-image">build image</a>. For a usage example, see <a href="###upload-to-ecr">Deploy To Kubernetes</a> below.</p>
<p>There are four different variables that CircleCI will need to access <em>per environment</em>. Our helper script expects environment variables to be named according to the list below where <code>&lt;ENVIRONMENT&gt;</code> should be replaced by some identifier of your choosing (eg.: <code>STAGING</code>, <code>PRODUCTION</code>).
- <code>KUBE_ENV_&lt;ENVIRONMENT&gt;_NAME</code> - the full name of the cluster (eg.: <code>live-1.cloud-platform.service.justice.gov.uk</code>)
- <code>KUBE_ENV_&lt;ENVIRONMENT&gt;_NAMESPACE</code> - the name of the <code>Namespace</code> (see <a href="/tasks.html#creating-a-cloud-platform-environment">Create a namespace</a>)
- <code>KUBE_ENV_&lt;ENVIRONMENT&gt;_CACERT</code> - the CA Certificate for the cluster, can be acquired from the <code>Secret</code> that is generated for the <code>ServiceAccount</code>
- <code>KUBE_ENV_&lt;ENVIRONMENT&gt;_TOKEN</code> - the access token generated for the <code>ServiceAccount</code>. Please note, you should first base64 decode the token value you retrieve from the secret <a href="###creating-a-service-account-for-circleci">in the previous section</a>, e.g. <code>echo &lt;thereallylongstringthatyougetback&gt; | base64 --decode</code>.</p>
<h5 id="creating-the-config-yml">Creating the config.yml</h5><p>CircleCI uses a YAML file to identify how you want your testing environment set up and what tests you want to run. On CircleCI 2.0, this file must be called <code>config.yml</code> and must be in a hidden folder called <code>.circleci</code> .</p>
<p><a href="https://circleci.com/docs/2.0/tutorials/">Tutorial</a> on creating a config.yml file. As long as you are building a Docker image you can configure Circle however you wish. The only additional configuration you will need to add is to upload an image to ECR and deploy to Kubernetes:</p>
<h6 id="upload-to-ecr">Upload to ECR</h6><p>Example of how you can push a built docker image to an ECR repository:</p>
<div class="highlight"><pre class="highlight yaml"><code><span class="pi">-</span> <span class="na">deploy</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">Push application Docker image</span>
    <span class="na">command</span><span class="pi">:</span> <span class="pi">|</span>
      <span class="no">$(aws ecr get-login --no-include-email)</span>
      <span class="no">docker tag app "${ECR_ENDPOINT}/${GITHUB_TEAM_NAME_SLUG}/${CIRCLE_PROJECT_REPONAME}:${CIRCLE_SHA1}"</span>
      <span class="no">docker push "${ECR_ENDPOINT}/${GITHUB_TEAM_NAME_SLUG}/${CIRCLE_PROJECT_REPONAME}:${CIRCLE_SHA1}"</span>
      <span class="no">if [ "${CIRCLE_BRANCH}" == "master" ]; then</span>
        <span class="no">docker tag app "${ECR_ENDPOINT}/${GITHUB_TEAM_NAME_SLUG}/${CIRCLE_PROJECT_REPONAME}:latest"</span>
        <span class="no">docker push "${ECR_ENDPOINT}/${GITHUB_TEAM_NAME_SLUG}/${CIRCLE_PROJECT_REPONAME}:latest"</span>
      <span class="no">fi</span>
</code></pre></div><h6 id="deploy-to-kubernetes">Deploy to Kubernetes</h6><p>We provide a docker image that simplifies the CircleCI configuration by encapsulating the authentication process in a script. For example, given a configured <code>DEVELOPMENT</code> environment (see the section on environment variables above):</p>
<div class="highlight"><pre class="highlight yaml"><code><span class="na">deploy_development</span><span class="pi">:</span>
  <span class="na">docker</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">image</span><span class="pi">:</span> <span class="s">${ECR_ENDPOINT}/cloud-platform/tools:circleci</span>
  <span class="na">steps</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">checkout</span>
    <span class="pi">-</span> <span class="na">deploy</span><span class="pi">:</span>
        <span class="na">name</span><span class="pi">:</span> <span class="s">Helm deployment</span>
        <span class="na">command</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="no">setup-kube-auth</span>
          <span class="no">kubectl config use-context development</span>
          <span class="no">if [ "${CIRCLE_BRANCH}" == "master" ]; then</span>
            <span class="no">helm upgrade ${APPLICATON_DEPLOY_NAME} ./helm_deploy/django-app/. \</span>
                          <span class="no">--install \</span>
                          <span class="no">--tiller-namespace=${NON_PROD_NS} \</span>
                          <span class="no">--namespace=${NON_PROD_NS} \</span>
                          <span class="no">--set image.repository="${ECR_ENDPOINT}/${GITHUB_TEAM_NAME_SLUG}/${CIRCLE_PROJECT_REPONAME}" \</span>
                          <span class="no">--set image.tag="latest" \</span>
                          <span class="no">--set deploy.host="${APPLICATION_HOST_URL}" \</span>
                          <span class="no">--set replicaCount="4" \</span>
                          <span class="no">--debug</span>
          <span class="no">fi</span>
</code></pre></div>
<h2 id="cleaning-up">Cleaning up</h2><p>When you have finished with a namespace, please clean it up, along with any
additional AWS resources you created. This helps to keep the cloud platform
repositories well-organised, and speeds up deployments and changes to the
cluster (because the build process doesn&rsquo;t have to spend time managing
unnecessary resources). It also helps to keep our hosting costs down.</p>
<p>The resources to be removed are:</p>

<ul>
<li>The AWS ECR which stores your docker images</li>
<li>Your namespace in the cluster. This contains all of the pods, containers and
other cluster resources for your application.</li>
<li>Any other AWS resources (e.g. RDS/Elasticache instances, S3 buckets, etc.)</li>
</ul>
<p>Cleaning up a namespace is a multi-stage process, as follows:</p>

<ol>
<li>Delete any CI/CD pipeline you have created, which deploys into your
namespace. This should be done first, so that anything you delete is not
immediately recreated by your build pipeline.</li>
<li>Tell terraform to delete the AWS resources it created for you.</li>
<li>Remove your namespace code from the <a href="https://github.com/ministryofjustice/cloud-platform-environments">cloud-platform-environments</a> repository.</li>
<li>Delete all of the kubernetes resources inside your namespace.</li>
<li>Delete your namespace from the cluster.</li>
</ol>
<p>The first step depends on how you have set up your CI/CD pipeline, and is not
covered here.</p>
<h3 id="2-tell-terraform-to-delete-your-aws-resources">2. Tell terraform to delete your AWS resources</h3><p>AWS resources are created by adding terraform code to the <code>resources</code> directory
in your namespace&rsquo;s folder in the <a href="https://github.com/ministryofjustice/cloud-platform-environments">cloud-platform-environments</a> repository:</p>
<div class="highlight"><pre class="highlight plaintext"><code> cloud-platform-environments/namespaces/live-1.cloud-platform.service.justice.gov.uk/[your namespace]/resources/
</code></pre></div><p>To get terraform to delete the resources it created, you need to delete all the
<code>\*.tf</code> files in this directory <strong>except <code>main.tf</code></strong></p>
<p>If you delete <code>main.tf</code> at this point, terraform has no way of knowing it is
responsible for managing any resources in the namespace, so it will not delete
anything. By leaving <code>main.tf</code> but nothing else, you are telling terraform that
it should manage resources for this namespace, but that there should be no
resources, so terraform will delete any resources that do exist.</p>
<p>Once you have deleted the other <code>*.tf</code> files from your namespace&rsquo;s resources
folder, raise a <a href="https://help.github.com/en/articles/about-pull-requests">PR</a> to get your changes merged. As soon as this happens, the
cloud platform build pipeline will run, and your AWS resources will be deleted.</p>
<h3 id="3-remove-your-namespace-code-from-the-cloud-platform-environments-repository">3. Remove your namespace code from the cloud-platform-environments repository</h3><p>After your change to delete all the <code>\*.tf</code> files except <code>main.tf</code> has been
merged, please raise an additional <a href="https://help.github.com/en/articles/about-pull-requests">PR</a> removing the whole of your namespace code
from the <a href="https://github.com/ministryofjustice/cloud-platform-environments">cloud-platform-environments</a> repository.</p>
<p>i.e. deleting the whole of the directory:</p>
<div class="highlight"><pre class="highlight plaintext"><code> cloud-platform-environments/namespaces/live-1.cloud-platform.service.justice.gov.uk/[your namespace]
</code></pre></div><p>Merging this <a href="https://help.github.com/en/articles/about-pull-requests">PR</a> will prevent the cloud platform build pipeline from recreating
your namespace, after it is deleted.</p>
<h3 id="4-delete-all-of-the-kubernetes-resources-inside-your-namespace">4. Delete all of the kubernetes resources inside your namespace.</h3><p>In your working copy of your application code, you can use the kubernetes
deployment yaml files to delete your namespace and all the kubernetes resources
within it.</p>
<p>Assuming your current working directory is a working copy of your application,
and that your kubernetes deployment yaml files are in a directory called
<code>kubernetes_deploy</code>, immediately below your current working directory, you
would run the following command to delete everything within your namespace.</p>
<div class="highlight"><pre class="highlight plaintext"><code>kubectl delete --filename kubernetes_deploy --namespace [your namespace]
</code></pre></div><p>This is analogous to using <code>kubectl apply</code> to create the resources from your
YAML files, but it will delete all the named resources.</p>
<p>If you are using <a href="https://helm.sh">Helm</a>, the equivalent command is:</p>
<div class="highlight"><pre class="highlight plaintext"><code>helm delete --purge
</code></pre></div><h3 id="5-delete-your-namespace-from-the-cluster">5. Delete your namespace from the cluster.</h3><p>Deleting a namespace requires admin access to the cluster.</p>
<p>Please raise a <a href="https://help.github.com/en/articles/about-pull-requests">PR</a> against the <a href="https://github.com/ministryofjustice/cloud-platform-environments">cloud-platform-environments</a> repository,
specifying the namespace you would like the team to delete.</p>
<h3 id="summary">Summary</h3><p>Removing your namespace and associated resources is a multi-stage process:</p>

<ol>
<li>Stop any CI/CD process from recreating everything</li>
<li>Get terraform to delete AWS resources</li>
<li>Remove the code that defines your namespace</li>
<li>Remove everything inside the namespace</li>
<li>Tell the cloud platform team to delete the namespace</li>
</ol>




<h2 id="monitoring-applications">Monitoring Applications</h2>
<h3 id="using-the-cloud-platform-prometheus-alertmanager-and-grafana">Using the Cloud Platform Prometheus, AlertManager and Grafana</h3><h4 id="using-the-cloud-platform-prometheus-alertmanager-and-grafana-introduction">Introduction</h4><p>Prometheus, AlertManager and Grafana have been installed on Live-0 to ensure the reliability and availability of the Cloud Platform. This document will briefly outline how to access the monitoring tools and where to find further information.</p>
<h4 id="what-is-prometheus">What is Prometheus</h4><p>Prometheus is an open-source systems monitoring and alerting toolkit originally built at SoundCloud. The Cloud Platform uses <a href="https://github.com/coreos/prometheus-operator">Prometheus Operator from CoreOS</a> which allows a number of Prometheus instances to be installed on a cluster.</p>
<p>Prometheus scrapes metrics from instrumented jobs, either directly or via an intermediary push gateway for short-lived jobs. It stores all scraped samples locally and runs rules over this data to either aggregate and record new time series from existing data or generate alerts. Grafana or other API consumers can be used to visualize the collected data.</p>
<h4 id="what-is-alertmanager">What is AlertManager</h4><p>The Alertmanager handles alerts sent by client applications such as the Prometheus server. It takes care of deduplicating, grouping, and routing them to the correct receiver integration such PagerDuty. It also takes care of silencing and inhibition of alerts.</p>
<h4 id="what-is-grafana">What is Grafana</h4><p>Grafana allows you to query, visualize, alert on and understand your metrics no matter where they are stored. Create, explore, and share dashboards with your team and foster a data driven culture.</p>
<h5 id="creating-dashboards">Creating dashboards</h5><p>Grafana is set up as a stateless app, managed entirely through code. This also helps achieve better availability. However, it means that dashboards will not persist in its database. To create a dashboard:</p>

<ol>
<li><p>Login to Grafana (see the links below) with your GitHub account. All users are able to edit dashboards but cannot save the changes. Find the dashboard titled &lsquo;Blank Dashboard&rsquo; and modify it as you see fit.</p></li>
<li><p>Once happy with your dashboard, click the share icon on the top right corner, select the <code>Export</code> tab, check the <code>Export for sharing externally</code> box and click on <code>View JSON</code>. Copy the JSON string into a <code>ConfigMap</code> according to the example below.</p></li>
</ol>
<div class="highlight"><pre class="highlight plaintext"><code>---
apiVersion: v1
kind: ConfigMap
metadata:
  name: &lt;my-dashboard&gt;
  namespace: &lt;my-namespace&gt;
  labels:
    grafana_dashboard: ""
data:
  my-dashboard.json: |
    {
      [ ... ]
    }
</code></pre></div><p>Make sure you&rsquo;ve included the <code>label</code> and that the JSON string is properly indented. Also, name of the key in the <code>ConfigMap</code> must end in <code>-dashboard.json</code>. Please note that you can have multiple dashboards exported in a single <code>ConfigMap</code> as well.</p>

<ol>
<li>Use <code>kubectl</code> to apply the <code>ConfigMap</code> above, your dashboard should be visible in Grafana shortly.</li>
</ol>
<h4 id="how-to-access-monitoring-tools">How to access monitoring tools</h4><p>All links provided below require you to authenticate with your Github account.</p>
<p>Prometheus: <a href="https://prometheus.apps.live-1.cloud-platform.service.justice.gov.uk">https://prometheus.apps.live-1.cloud-platform.service.justice.gov.uk</a></p>
<p>AlertManager: <a href="https://alertmanager.apps.live-1.cloud-platform.service.justice.gov.uk/">https://alertmanager.apps.live-1.cloud-platform.service.justice.gov.uk</a></p>
<p>Grafana: <a href="https://grafana.apps.live-1.cloud-platform.service.justice.gov.uk">https://grafana.apps.live-1.cloud-platform.service.justice.gov.uk</a></p>
<h4 id="further-documentation">Further documentation</h4><p><a href="https://prometheus.io/docs/prometheus/latest/querying/basics">Prometheus querying</a></p>
<p><a href="https://prometheus.io/docs/alerting/alertmanager">AlertManager</a></p>
<p><a href="https://prometheus.io/docs/introduction/overview/###architecture">Architecture</a></p>

<h3 id="creating-your-own-custom-alerts">Creating your own custom alerts</h3><h4 id="overview">Overview</h4><p>Alertmanager allows you define your own alert conditions based on <a href="https://prometheus.io/docs/prometheus/latest/querying/basics">Prometheus expression language</a> expressions.</p>
<p>The aim of this document is to provide you with the necessary information to create and send application specific alerts to a Slack channel of your choosing.</p>
<h4 id="prerequisites">Prerequisites</h4><p>This guide assumes the following:</p>

<ul>
<li>You have <a href="/tasks.html#creating-a-cloud-platform-environment">created a namespace for your application</a></li>
</ul>
<h4 id="creating-a-slack-webhook-and-amend-alertmanager">Creating a slack webhook and amend Alertmanager</h4><p>This step requires the Cloud Platform team to create a receiver in <a href="https://github.com/ministryofjustice/cloud-platform-infrastructure/blob/master/terraform/cloud-platform-components/templates/prometheus-operator.yaml.tpl###L115">Alertmanager</a> and a <a href="https://api.slack.com/incoming-webhooks">Slack webhook</a>.</p>
<p>Create a ticket to request a new alert route in Alertmanager. The team will need the following information:</p>

<ul>
<li>namespace name</li>
<li>team name</li>
<li>application name</li>
<li>slack channel</li>
</ul>
<p>The team will provide you with a &ldquo;<code>custom severity level</code>&rdquo; that&rsquo;ll need to be defined in the next step. Please copy it to your clipboard.</p>
<h4 id="create-a-prometheusrule">Create a PrometheusRule</h4><p>A <code>PrometheusRule</code> is a custom resource that defines your triggered alert. This file will contain the alert name, promql expression and time of check.</p>
<p>To create your own custom alert you&rsquo;ll need to fill in the template below and deploy it to your namespace (tip: you can check rules in your namespace by running <code>kubectl get prometheusrule -n &lt;namespace&gt;</code>).</p>

<ul>
<li>Create a file called <code>prometheus-custom-rules-&lt;application_name&gt;.yaml</code></li>
<li>Copy in the template below and replace the bracket values, specifying the requirements of your alert. The <code>&lt;custom_severity_level&gt;</code> field is the value you were passed earlier.</li>
</ul>
<div class="highlight"><pre class="highlight yaml"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">monitoring.coreos.com/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">PrometheusRule</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">&lt;namespace&gt;</span>
  <span class="na">labels</span><span class="pi">:</span>
    <span class="na">role</span><span class="pi">:</span> <span class="s">alert-rules</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">prometheus-custom-rules-&lt;application_name&gt;</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">groups</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">application-rules</span>
    <span class="na">rules</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">alert</span><span class="pi">:</span> <span class="s">&lt;alert_name&gt;</span>
      <span class="na">expr</span><span class="pi">:</span> <span class="s">&lt;alert_query&gt;</span>
      <span class="na">for</span><span class="pi">:</span> <span class="s">&lt;check_time_length&gt;</span>
      <span class="na">labels</span><span class="pi">:</span>
        <span class="na">severity</span><span class="pi">:</span> <span class="s">&lt;custom_severity_level&gt;</span>
      <span class="na">annotations</span><span class="pi">:</span>
        <span class="na">message</span><span class="pi">:</span> <span class="s">&lt;alert_message&gt;</span>
        <span class="na">runbook_url</span><span class="pi">:</span> <span class="s">&lt;http://my-support-docs&gt;</span>
</code></pre></div>
<ul>
<li>Run <code>kubectl apply -f prometheus-custom-rules-&lt;application_name&gt;.yaml -n &lt;namespace&gt;</code></li>
</ul>
<p>A working example of this would be:</p>
<div class="highlight"><pre class="highlight yaml"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">monitoring.coreos.com/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">PrometheusRule</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">creationTimestamp</span><span class="pi">:</span> <span class="no">null</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">monitoring</span>
  <span class="na">labels</span><span class="pi">:</span>
    <span class="na">role</span><span class="pi">:</span> <span class="s">alert-rules</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">prometheus-custom-rules-my-application</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">groups</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">node.rules</span>
    <span class="na">rules</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">alert</span><span class="pi">:</span> <span class="s">Quota-Exceeded</span>
      <span class="na">expr</span><span class="pi">:</span> <span class="s">100 * kube_resourcequota{job="kube-state-metrics",type="used",namespace="monitoring"} / ignoring(instance, job, type) (kube_resourcequota{job="kube-state-metrics",type="hard"} &gt; 0) &gt; 90</span>
      <span class="na">for</span><span class="pi">:</span> <span class="s">5m</span>
      <span class="na">labels</span><span class="pi">:</span>
        <span class="na">severity</span><span class="pi">:</span> <span class="s">cp-team</span>
      <span class="na">annotations</span><span class="pi">:</span>
        <span class="na">message</span><span class="pi">:</span> <span class="s">Namespace {{ $labels.namespace }} is using {{ printf "%0.0f" $value}}% of its {{ $labels.resource }} quota.</span>
        <span class="na">runbook_url</span><span class="pi">:</span> <span class="s">https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md###alert-name-kubequotaexceeded</span>
</code></pre></div><p>The <code>alert</code> name, <code>message</code> and <code>runbook_url</code> annotations will be sent to the Slack channel when the rule has been triggered.</p>
<p>You can view the applied rules with the following command:</p>
<div class="highlight"><pre class="highlight shell"><code>kubectl <span class="nt">-n</span> &lt;namespace&gt; describe prometheusrules prometheus-custom-rules-&lt;application_name&gt;
</code></pre></div><h4 id="prometheusrule-examples">PrometheusRule examples</h4><p>If you&rsquo;re struggling for ideas on how and which alerts to setup, please see some examples <a href="https://github.com/ministryofjustice/cloud-platform-infrastructure/blob/master/terraform/cloud-platform-components/resources/prometheusrule-examples/application-alerts.yaml">here</a>.</p>
<h4 id="advisory-note-prometheusrules-status-incase-of-dr-requirement-for-a-new-prometheus-install">Advisory Note: PrometheusRules status incase of DR/requirement for a new Prometheus Install</h4><p>The  <code>PrometheusRule</code> is a <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/##customresourcedefinitions">CRD</a> that declaratively defines a desired Prometheus rule to be consumed by Prometheus and applied using a YAML file. However, if for any reason Prometheus has to be uninstalled, <code>all PrometheusRules are removed with the CRD.</code></p>
<p>We recommend all PrometheusRules to be added to the <a href="https://github.com/ministryofjustice/cloud-platform-environments">Environments Repo</a> within the namespace folder the rules refer to. This will ensure all rules are applied/present at all times.</p>
<p>PrometheusRules can still be tested/amended/applied manually, then a PR can be created to add to the Environments Repo when ready.</p>
<h4 id="further-reading">Further reading</h4>
<ul>
<li><a href="https://github.com/coreos/prometheus-operator/blob/master/Documentation/user-guides/getting-started.md">Prometheus Operator - Getting Started</a></li>
<li><a href="https://github.com/coreos/prometheus-operator/blob/master/Documentation/user-guides/alerting.md">Alerting</a></li>
</ul>

<h3 id="getting-application-metrics-into-prometheus">Getting Application Metrics into Prometheus</h3><p>Prometheus collects metrics from monitored targets by scraping metrics HTTP endpoints on these targets. There are two ways to create a metrics endpoint. The first is when the metrics endpoint is embedded within the application referred to as <code>instrumentation</code>. The second is when the metrics endpoint is part of a deployed process that bridges the gap between Prometheus and systems that do not export metrics in the prometheus format, this is called an <code>exporter</code>.</p>
<p>The following exporters are installed as part of the Cloud Platform cluster build:</p>

<ul>
<li>kubeEtcd</li>
<li>kubeApiServer</li>
<li>kubeDns</li>
<li>kubeControllerManager</li>
<li>kubeScheduler</li>
<li>kube-state-metrics</li>
<li>nodeExporter</li>
<li>kubelet</li>
</ul>
<p>Click <a href="https://github.com/prometheus/docs/blob/master/content/docs/instrumenting/exporters.md">here</a> for a list of exporters and client libraries listed on the official Prometheus Github repo.</p>
<h4 id="instrumentation-of-the-cloud-platform-reference-application">Instrumentation of The Cloud-Platform Reference Application</h4><p>The <a href="https://github.com/ministryofjustice/cloud-platform-reference-app">Cloud Platform Reference Application</a> has <code>instrumentation</code> setup using <a href="https://github.com/korfuri/django-prometheus">django-prometheus</a>. The default install steps were followed which created a metrics endpoint.</p>
<p>See screenshot below of how the metrics endpoint looks on a browser:
<a href="https://raw.githubusercontent.com/ministryofjustice/cloud-platform-user-docs/master/images/metrics-endpoint.png" target="_blank" rel="noopener noreferrer"><img src="https://raw.githubusercontent.com/ministryofjustice/cloud-platform-user-docs/master/images/metrics-endpoint.png" alt="Image of metrics" /></a></p>
<h4 id="create-a-service-to-expose-pods">Create a Service to expose Pods</h4><p>Scraping an exporter or separate metrics port requires a service that targets the Pod(s) of the exporter or application.</p>
<p>Example:</p>
<div class="highlight"><pre class="highlight yaml"><code><span class="na">kind</span><span class="pi">:</span> <span class="s">Service</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">my-app-service</span>
  <span class="na">labels</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">my-app</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">my-app</span>
  <span class="na">ports</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">protocol</span><span class="pi">:</span> <span class="s">TCP</span>
    <span class="na">port</span><span class="pi">:</span> <span class="s">8000</span>
    <span class="na">targetPort</span><span class="pi">:</span> <span class="s">8000</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">metrics</span>
  <span class="na">type</span><span class="pi">:</span> <span class="s">NodePort</span>
</code></pre></div><h4 id="create-a-service-monitor">Create a Service-Monitor</h4><p>A <code>ServiceMonitor</code> is a resource the Prometheus Operator introduces for Kubernetes that describes the set of targets to be monitored by Prometheus</p>
<p>Service Monitor Architecture
<a href="https://raw.githubusercontent.com/ministryofjustice/cloud-platform-user-docs/master/images/service-monitor-arch.png" target="_blank" rel="noopener noreferrer"><img src="https://raw.githubusercontent.com/ministryofjustice/cloud-platform-user-docs/master/images/service-monitor-arch.png" alt="Image of Service-Monitor Architecture" /></a></p>
<p>Example:</p>
<div class="highlight"><pre class="highlight yaml"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">monitoring.coreos.com/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ServiceMonitor</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">my-app</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">my-app</span>
  <span class="na">endpoints</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">port</span><span class="pi">:</span> <span class="s">metrics</span>
    <span class="na">interval</span><span class="pi">:</span> <span class="s">15s</span>
</code></pre></div><p>More detailed information about service-monitors can be found <a href="https://github.com/coreos/prometheus-operator/blob/master/Documentation/user-guides/running-exporters.md">here</a></p>
<h4 id="networkpolicy-for-monitoring-namespace">NetworkPolicy for Monitoring Namespace</h4><p>By default, all connections from outside a namespace are blocked, therefore a network policy is required for the <code>monitoring</code> namespace to be able to connect into an application namespace to scrape the metrics endpoint.</p>
<p>Example:</p>
<div class="highlight"><pre class="highlight yaml"><code><span class="na">kind</span><span class="pi">:</span> <span class="s">NetworkPolicy</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">networking.k8s.io/v1</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">allow-prometheus-scraping</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">my-app-namespace</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">podSelector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">my-app</span>
  <span class="na">policyTypes</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">Ingress</span>
  <span class="na">ingress</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">from</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">namespaceSelector</span><span class="pi">:</span>
        <span class="na">matchLabels</span><span class="pi">:</span>
          <span class="na">component</span><span class="pi">:</span> <span class="s">monitoring</span>
</code></pre></div><p>You can view your current NetworkPolices with the following command:</p>
<div class="highlight"><pre class="highlight shell"><code>kubectl <span class="nt">-n</span> &lt;namespace&gt; get networkpolicies
</code></pre></div><h4 id="advisory-note-applications-configured-to-use-multiple-processes">Advisory note: Applications configured to use multiple processes</h4><p>If you&rsquo;re using a pre-forking web server (like unicorn or puma for Ruby, or gunicorn for Python) and have it configured to use multiple processes, then you need to use a Prometheus client library which supports exporting metrics from multiple processes. Not all the official clients do that. If you don&rsquo;t use a library which supports this, then requests to <code>/metrics</code> could be served by any of the processes, which would mean Prometheus sees inconsistent data on each scrape</p>




<h2 id="application-logging">Application Logging</h2>
<h3 id="application-log-collection-and-storage">Application Log Collection and Storage</h3><h4 id="application-log-collection-and-storage-overview">Overview</h4><p>The Cloud Platform supports the ability for application logs to be collected, stored, and accessed.</p>
<p>Logs are collected automatically, via Fluentd, stored in an AWS-Hosted ElasticSearch Cluster, and accessed via AWS-Hosted Kibana dashboard.</p>
<h4 id="log-collection">Log Collection</h4><p>Fluentd is a cluster-wide log collection service that runs in it&rsquo;s own dedicated environment.</p>
<p>The Fluentd application is configured with cluster-wide read permissions. The only requirement for Fluentd to start automatically collecting your application&rsquo;s logs is to have your application output logs to <code>stdout</code>.</p>
<h4 id="log-storage">Log Storage</h4><p>As an application engineer, you won&rsquo;t really need to pay much attention to how the logs are stored, as this is handled by the Cloud Platform team.</p>
<p>The logs are shipped from Fluentd and stored in an AWS-Hosted ElasticSearch cluster. All application logs are retained for 30 days, before being curated for deletion.</p>

<h3 id="accessing-application-log-data">Accessing Application Log Data</h3><h4 id="accessing-application-log-data-overview">Overview</h4><p>This document is intended to assist engineers in accessing application and system logs stored in a centralized Elasticsearch cluster.</p>
<h4 id="access-kibana">Access Kibana</h4><p>The Cloud Platform collects, indexes and presents your application and system log data enabling you to query using Kibana’s standard query language (based on Lucene query syntax).</p>
<p>To access Kibana, follow the appropriate link below and authenticate with your GitHub credentials:</p>
<h5 id="live-1-cluster">Live-1 Cluster</h5><p><a href="https://kibana.apps.live-1.cloud-platform.service.justice.gov.uk/_plugin/kibana/">https://kibana.apps.live-1.cloud-platform.service.justice.gov.uk/plugin/kibana/</a></p>
<h5 id="live-0-cluster">Live-0 Cluster</h5><p><a href="https://kibana.apps.cloud-platform-live-0.k8s.integration.dsd.io/_plugin/kibana/">https://kibana.apps.cloud-platform-live-0.k8s.integration.dsd.io/plugin/kibana/</a></p>
<h4 id="using-kibana">Using Kibana</h4><p>As a quick example, we will filter down to the logs of a particular environment.</p>
<p>1) On the Kibana dashboard, select the &lsquo;Discover&rsquo; tab.</p>
<p>2) Select &#39;Add a filter +&rsquo;</p>
<p>3) Filter <code>kubernetes.namespace_name</code>, with operator <code>is</code> and the value equal to your environment name.</p>
<p>More in-depth guides on using Kibana can be found below:</p>
<p><a href="https://www.elastic.co/guide/en/kibana/6.3/search.html">https://www.elastic.co/guide/en/kibana/6.3/search.html</a></p>
<p><a href="https://www.elastic.co/guide/en/beats/packetbeat/current/kibana-queries-filters.html">https://www.elastic.co/guide/en/beats/packetbeat/current/kibana-queries-filters.html</a></p>




<h2 id="other-topics">Other Topics</h2>
<h3 id="git-crypt">Git-Crypt</h3><p>We use <code>git-crypt</code> to ensure that application secrets are encrypted at rest in git.</p>
<h4 id="git-crypt-prerequisites">Prerequisites</h4>
<ol>
<li>Install <a href="https://gnupg.org/">GPG</a></li>
<li>Install <a href="https://www.agwa.name/projects/git-crypt/">git-crypt</a></li>
<li>Generate a key pair, if you don&rsquo;t have one already. The <a href="https://help.github.com/articles/generating-a-new-gpg-key/">GitHub documentation</a> is a good reference.</li>
<li>Push your public key to a key server: <code>gpg --send-keys PUBKEYID</code></li>
<li>Add the pubkey to your GitHub account, again, following <a href="https://help.github.com/articles/adding-a-new-gpg-key-to-your-github-account/">the documentation</a></li>
</ol>
<h4 id="setup">Setup</h4>
<ul>
<li>If the repository has not been setup before, please follow the <a href="https://github.com/AGWA/git-crypt##using-git-crypt">git-crypt documentation</a> to do so.</li>
</ul>
<p>otherwise,</p>

<ul>
<li>Share your <code>PUBKEYID</code> with an existing member of the CloudPlatforms team. They will need to trust your key and add you to the repository (see git-crypt documentation above).</li>
</ul>
<h4 id="usage">Usage</h4><p>Once the above has been setup, update your local repository clone and unlock the secrets:</p>
<div class="highlight"><pre class="highlight plaintext"><code>$ git pull
$ git-crypt unlock
</code></pre></div><p>From this point on, <code>git-crypt</code> operates transparently.</p>
<p>You can verify the status of files by using <code>git-crypt status</code>.</p>

<h3 id="secrets-overview">Secrets overview</h3><p>We identify secrets as one of three kinds:
- user secrets
- system secrets
- application secrets</p>
<h4 id="user-secrets">User Secrets</h4><p>They are essentially any kind of secret that is owned by a specific user (eg. GitHub or AWS credentials). The user is responsible for securely managing these secrets, typically using a password manager and they should not be shared with other individuals or used in applications.</p>
<h4 id="system-secrets">System Secrets</h4><p>They are secrets used in system components, usually configured by someone who manages, configures or supports the system. For example, when setting up a CI pipeline, the credentials it uses to fetch the source code and push the produced artifacts to a repository are considered system secrets.</p>
<p>These should not be tied to an individual user but machine users should be employed. The responsibility of managing these secrets securely lies with the owner of the system.</p>
<h4 id="application-secrets">Application Secrets</h4><p>These are the secrets that the application requires at runtime. Some examples are: API keys for third-party services, keys that applications might use to communicate with each other, database credentials, cookie encryption keys and so on.</p>
<p>This kind of secrets falls under the shared responsibility model:</p>

<ul>
<li><p>the owners of the application are responsible for securely managing the secrets at rest (eg. using <a href="/archive.html#git-crypt">git-crypt</a> to encrypt them alongside the source code) and also for managing access to the secrets once they&rsquo;ve been added to an environment,</p></li>
<li><p>the Cloud Platform team, on the other hand, is responsible for ensuring the secrets remain secure inside the environment.</p></li>
</ul>

<h3 id="kubectl-quick-reference">Kubectl quick reference</h3><p>This document acts as a quick reference to <code>kubectl</code>, listing some of the most common operations.</p>
<p>The examples here only address the most basic approach to these operations. For more options, please refer to the command-line help of <code>kubectl</code> subcommands.</p>
<p>There is also a more detailed <a href="https://kubernetes.io/docs/reference/kubectl/cheatsheet/">cheatsheet</a> in the official kubernetes documentation.</p>
<h6 id="inspecting-running-instances-of-the-application">Inspecting running instances of the application</h6><p>To list running <code>Pods</code>:
<code>
$ kubectl -n &lt;namespace&gt; get pods
</code>
To view details for a <code>Pod</code>:
<code>
$ kubectl -n &lt;namespace&gt; describe pod &lt;pod&gt;
</code></p>
<h6 id="viewing-logs">Viewing logs</h6><p>To access the logs of a running container:
<code>
$ kubectl -n &lt;namespace&gt; logs &lt;pod&gt;
</code></p>
<h6 id="viewing-kubernetes-events">Viewing kubernetes events</h6><p>To see kubernetes events, which can help debugging:
<code>
$ kubectl -n &lt;namespace&gt; get events
</code></p>
<h6 id="container-shell">Container shell</h6><p>You can get a shell inside a running container:
<code>
$ kubectl -n &lt;namespace&gt; exec -it &lt;pod&gt; sh
</code>
https://kubernetes.io/docs/tasks/debug-application-cluster/get-shell-running-container/</p>
<h6 id="pod-port-forwarding">Pod port-forwarding</h6><p>To forward port <code>5000</code> on <code>localhost</code> to port <code>5001</code> in the <code>Pod</code>:
<code>
$ kubectl -n &lt;namespace&gt; port-forward &lt;pod&gt; 5000:5001
</code>
https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/</p>

<h3 id="cloud-platform-support">Cloud Platform Support</h3><p><a href="https://docs.google.com/document/d/1M89TXQJIQAqu8yb2wzatlI8PgsXrgOi-GxLtB76XgjU/edit?usp=sharing">https://docs.google.com/document/d/1M89TXQJIQAqu8yb2wzatlI8PgsXrgOi-GxLtB76XgjU/edit?usp=sharing</a></p>

<h3 id="zero-downtime-deployments">Zero Downtime Deployments</h3><h4 id="zero-downtime-deployments-introduction">Introduction</h4><p>Zero Downtime Deployments are a significant feature of the Cloud Platform, that bring a host of advantages.</p>
<h4 id="rolling-updates">Rolling Updates</h4><p>Rolling updates introduce the ability to update an application without any downtime.</p>
<p>A rolling update works by ensuring there is always one extra Pod than the maximum number stated in the deployment.</p>
<p>The new deployment is applied incrementally, usually one to two Pods at a time until all Pods are running the latest version. How the deployment is rolled out, can be configured by the user. More information about configuring a rolling update can be found <a href="https://kubernetes.io/docs/tasks/run-application/rolling-update-replication-controller/">here</a>.</p>
<p>If an application is exposed publicly, traffic will only be routed to the available Pods. However, this is only the case if the user configured <code>readinessProbes</code> correctly. This is a large topic, so more information can be found <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/">here</a>.</p>
<h5 id="the-major-advantage">The Major Advantage</h5><p>Where rolling updates really brings benefit is the enabling of Continuous Integration and Continuous Delivery.</p>
<p>The ability to constantly update your application, with zero downtime, brings a host of benefits.</p>
<h5 id="rolling-updates-further-reading">Further Reading</h5><p>If you&rsquo;d like to read more in-depth into rolling updates, then Kubernetes has some great documentation <a href="https://kubernetes.io/docs/tutorials/kubernetes-basics/update/update-intro/">here</a>.</p>
<h5 id="readiness-liveness-probes-and-ssl-in-rails-applications">Readiness/Liveness probes and SSL in Rails applications</h5><p>For zero downtime deployments, you will need a readiness probe in your application, so that the cluster knows when your container is ready to receive traffic. You will also need a liveness probe, so that the cluster knows if it needs to restart your container after a crash.</p>
<p>SSL will be terminated outside of your pod, so your probes will need to respond to HTTP requests. However, Ruby on Rails applications are sometimes configured to only respond to HTTPS traffic (by adding <code>config.force_ssl = true</code> in the <code>config/environments/production.rb</code> file).</p>
<p>In this case, the application will respond to any HTTP request with a redirect status code, asking the requester to resend the request to the equivalent HTTPS URL. This will cause your probes to fail, because the redirect will not be followed.</p>
<p>To fix this, the probe needs to tell the application that it is an HTTPS request, even though it isn&rsquo;t, so that the application will process the request rather than sending a redirect response. You can do this by adding some HTTP headers to your probe definitions like this:</p>
<div class="highlight"><pre class="highlight plaintext"><code>readinessProbe:
  httpGet:
    path: /ping.json
    port: 3000
    httpHeaders:
      - name: X-Forwarded-Proto
        value: https
      - name: X-Forwarded-Ssl
        value: "on"
</code></pre></div><p>This will send an HTTP request to <code>/ping.json</code>, but the rails application will respond as if it is HTTPS, and your probe should work as expected. This works for both readiness and liveness probes.</p>

<h3 id="contributing-to-this-document">Contributing to this document</h3><p>This guide is built using <a href="https://pages.github.com/">GitHub Pages</a>.</p>
<p>If you would like to contribute to this guide, please fork <a href="https://github.com/ministryofjustice/cloud-platform-user-docs">the repository</a>, make your changes and then raise a pull request.</p>

<h3 id="using-an-externally-managed-hostname">Using an externally-managed hostname</h3><h4 id="background">Background</h4><p>Every application running on Cloud Platform is able to use a hostname for their
HTTP endpoints, under a pre-defined DNS zone. For example, on the <code>live-1</code>
cluster, this would be <code>*.apps.live-1.cloud-platform.service.justice.gov.uk</code>. As
long as it is defined on the <code>Ingress</code> resource, it works automatically with a
wildcard TLS certificate.</p>
<p>However, most applications will typically need to be served on a <code>gov.uk</code>
hostname. These hostnames (or usually, DNS zones) are managed externally,
relative to the cluster, and there is a number of actions in order to set them
up for usage.</p>
<h4 id="using-an-externally-managed-hostname-setup">Setup</h4><h5 id="you-do-not-have-a-dns-zone-for-the-desired-hostname">You do not have a DNS zone for the desired hostname</h5><p>Please <a href="http://goo.gl/msfGiS">create a support ticket</a> providing as much
information as possible.</p>
<h5 id="you-already-have-a-dns-zone-for-the-desired-hostname">You already have a DNS zone for the desired hostname</h5><h6 id="gt-it-39-s-a-route53-zone">&gt; It&rsquo;s a Route53 zone</h6>
<ol>
<li><p><a href="http://goo.gl/msfGiS">Create a support ticket</a> requesting the <code>provider</code>
name for your <code>Certificate</code> (see the next step).</p></li>
<li><p>Create the <code>Certificate</code>, using the <code>provider</code> name from the previous step.
The <code>secretName</code> attribute defines the <code>Secret</code> where the certificate and key
material will be stored, in your namespace.</p></li>
</ol>
<div class="highlight"><pre class="highlight plaintext"><code>---
apiVersion: certmanager.k8s.io/v1alpha1
kind: Certificate
metadata:
  name: &lt;my-cert&gt;
  namespace: &lt;my-namespace&gt;
spec:
  secretName: &lt;my-cert-secret&gt;
  issuerRef:
    name: letsencrypt-production
    kind: ClusterIssuer
  commonName: '&lt;hostname&gt;'
  acme:
    config:
    - domains:
      - '&lt;hostname&gt;'
      dns01:
        provider: &lt;provider&gt;
</code></pre></div>
<ol>
<li>Make sure the certificate has been issued correctly, by checking its <code>Status</code>:</li>
</ol>
<div class="highlight"><pre class="highlight plaintext"><code>$ kubectl describe certificate &lt;my-cert&gt;
</code></pre></div>
<ol>
<li>You will need to update your <code>Ingress</code> spec to include the new hostname. <strong>Once your host is defined here, the cluster will take control of the DNS record and automatically adjust to point to the cluster.</strong></li>
</ol>
<div class="highlight"><pre class="highlight plaintext"><code>  apiVersion: extensions/v1beta1
  kind: Ingress
  metadata:
    name: &lt;my-ingress&gt;
    namespace: &lt;my-namespace&gt;
  spec:
    tls:
    - hosts:
      - my-app.apps.live-1.cloud-platform.service.justice.gov.uk
+   - hosts:
+     - &lt;hostname&gt;
+     secretName: &lt;my-cert-secret&gt;
    rules:
    - host: my-app.apps.live-1.cloud-platform.service.justice.gov.uk
      http:
        paths:
        - path: /
          backend:
            serviceName: &lt;my-svc&gt;
            servicePort: 80
+   - host: &lt;hostname&gt;
+     http:
+       paths:
+       - path: /
+         backend:
+           serviceName: &lt;my-svc&gt;
+           servicePort: 80
</code></pre></div><h6 id="gt-it-39-s-a-dns-zone-hosted-with-another-provider">&gt; It&rsquo;s a DNS zone hosted with another provider</h6><p>For the time being, we only support Route53 natively. Depending on the provider
we might be able to accommodate you or we might need to handle this manually, if possible.
Please <a href="http://goo.gl/msfGiS">create a support ticket</a>.</p>

<h3 id="ip-whitelisting">IP Whitelisting</h3><h4 id="nat-gateways">NAT Gateways</h4><p>Many applications use third-party tools for a variety of reasons, and many of these tools require IP Whitelisting.</p>
<p>The Cloud Platform uses NAT Gateways as its external IP Endpoints.</p>
<p>The IP addresses for the clusters are as follows:</p>
<h5 id="nat-gateways-live-0-cluster">Live-0 Cluster</h5><div class="highlight"><pre class="highlight plaintext"><code>52.17.133.167
34.251.93.81
34.247.134.240
</code></pre></div><h5 id="nat-gateways-live-1-cluster">Live-1 Cluster</h5><div class="highlight"><pre class="highlight plaintext"><code>35.178.209.113
3.8.51.207
35.177.252.54
</code></pre></div>
<h3 id="ecr-lifecycle-policy">ECR Lifecycle Policy</h3><h4 id="ecr-lifecycle-policy-overview">Overview</h4><p>ECR repositories created for use in the Cloud Platform will have a default lifecycle policy applied.</p>
<p>Due to some applications having a constant rate of images being pushed to their ECR repo, we found that the AWS limit of 1000 images was being hit by some teams.</p>
<p>After consulting with application teams, we decided to implement a lifecycle policy of <em>40 images</em> per ECR repo.</p>
<p>If you feel that you have a need to archive more than the last 40 images, please contact the Cloud Platform team, who can adjust or remove the lifecycle policy.</p>

<h3 id="applying-a-maintenance-page">Applying a Maintenance Page</h3><h4 id="applying-a-maintenance-page-overview">Overview</h4><p>This document will serve as a guide on how to apply a default
maintenance page to your application on the Cloud Platform.</p>
<h4 id="deploying-the-page">Deploying the page</h4><p>A repository has been created to store all the files related to the
maintenance page:</p>
<p><a href="https://github.com/ministryofjustice/cloud-platform-maintenance-page">cloud-platform-maintenance-page</a></p>
<p>The repository contains the manifest files needed to deploy a
standard maintenance page into your namespace. This directory also
contains the maintenance page HTML file, along with a DockerFile
to build an image to serve the maintenance page.</p>
<p>Within the <code>Kubectl_deploy</code> directory, there are 3 simple manifest
files that make up the deployment, <code>deploy.yaml</code>, <code>ingress.yaml</code>
and <code>service.yaml</code>.</p>
<p>To use this example, copy the files into your namespace and make
any changes you require, to tailor the maintenance page to your
service.</p>
<p>Once you have done this, the maintenance page will be deployed
into your namespace, ready for you to use as and when you need
it.</p>
<h5 id="maintenance-deploy-yaml">maintenance-deploy.yaml</h5><p>A notable part of this file is the <code>image</code> line, which points to
the ECR URI.</p>
<p>If you wish to customize the maintenance page, you must edit and
build the image and update the <code>image</code> value.</p>
<h5 id="maintenance-ingress-yaml">maintenance-ingress.yaml</h5><p>In this file, change the example <code>host</code> field to your applications
URL.</p>
<p>Rather than using this file, you may prefer to change your existing
<code>Ingress</code> so that the <code>backend</code> points to your maintenance page,
whenever you need to replace your service with the maintenance page.</p>
<p>This will ensure that you do not incur any downtime (by deleting
the previous ingress and creating a new one).</p>

<h2 id="live-1-migration-guide">Live 1 Migration Guide</h2><h3 id="live-1-migration-guide-overview">Overview</h3><p>After some long consideration of possible options, the decision has been made to migrate from the <code>live-0</code> cluster to the new <code>live-1</code> cluster.</p>
<p>The reason behind this decision is based on the need to move to a dedicated AWS account, which will be much easier to support, and the need to move away from the Ireland (EU) region to the London (UK) region.</p>
<p>The purpose of this document is to aid development teams in migrating their existing applications from <code>live-0</code> to <code>live-1</code>.</p>
<p>The migration steps that need to be taken may differ for individual applications.</p>
<p>The following steps are for an application that is considered to be fairly normal and deployed through CircleCI.</p>
<p>Appending these steps are a few extra consideration points, that are not covered in the example, but may apply to your application.</p>
<h3 id="accessing-the-live-1-cluster">Accessing the Live-1 cluster</h3><p>To access the <code>live-1</code> cluster, navigate to the <a href="https://login.apps.live-1.cloud-platform.service.justice.gov.uk">Kuberos configuration page</a>, and download your Kube config file.</p>
<p>Kubernetes provides a <a href="https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/#set-the-kubeconfig-environment-variable">brief guide</a> on how to set up <code>kubectl</code> to use multiple config files simultaneously.</p>
<p>You should now be able to switch contexts between the <code>live-0</code> and <code>live-1</code> clusters.</p>
<h3 id="generating-a-new-environment">Generating a new environment</h3><p>Start by following the guide to generate a new environment, this follows the same process as was followed for <code>live-0</code>, and you should use the same details as you did for your environment then.</p>
<p><a href="/tasks.html#create-an-environment">Environment generation guide.</a></p>
<p>Run a <code>kubectl get namespaces</code> to check your environment has been successfully created.</p>
<h3 id="generating-a-new-ecr-repository">Generating a new ECR repository</h3><p>Once you&rsquo;ve generated a new environment in the <code>live-1</code> cluster, you will need to generate a new ECR repository for your application to be pushed to.</p>
<p>The reason why the previous ECR repo can&rsquo;t be used is due to the new <code>live-1</code> cluster being hosted in a separate AWS account.</p>
<p>If you need reminding of the ECR creation process, please see the <a href="/tasks.html#creating-an-ecr-repository">user documentation</a>.</p>
<h3 id="changing-the-circleci-environment-variables">Changing the CircleCI environment variables</h3><p>Now that you have a new empty environment and ECR repository set-up, the next step is to point your existing CircleCI pipeline away from the <code>live-0</code> environment, to your new <code>live-1</code> environment.</p>
<p>This is done by replacing the CircleCI environment variables with the ones generated for your <code>live-1</code> environment and then rerunning the pipeline.</p>
<p>Our helper script expects environment variables to be named according to the list below where <code>&lt;ENVIRONMENT&gt;</code> should be replaced by some identifier of your choosing (eg.: <code>STAGING</code>, <code>PRODUCTION</code>).</p>
<p>The environment variables you will need to replace are as follows:</p>
<div class="table-container">
        <table>
          <tr>
<th>Variable</th>
<th style="text-align: center"></th>
</tr>
<tr>
<td><code>AWS_DEFAULT_REGION</code></td>
<td style="text-align: center">The default region will now be <code>eu-west-2</code>.</td>
</tr>
<tr>
<td><code>AWS_ACCESS_KEY_ID</code></td>
<td style="text-align: center">The access key can be found in the secret created by the ECR generation. This requires base64 decoding.</td>
</tr>
<tr>
<td><code>AWS_SECRET_ACCESS_KEY</code></td>
<td style="text-align: center">The secret key can be found in the secret created by the ECR generation. This requires base64 decoding.</td>
</tr>
<tr>
<td><code>ECR_ENDPOINT</code></td>
<td style="text-align: center">The ECR endpoint for all repos in <code>live-1</code> is <code>754256621582.dkr.ecr.eu-west-2.amazonaws.com</code></td>
</tr>
<tr>
<td><code>K8S_&lt;ENVIRONMENT&gt;_CLUSTER_CERT</code></td>
<td style="text-align: center">The cert is an attribute found in the <code>default-token</code> secret and does not need base64 decoding.</td>
</tr>
<tr>
<td><code>K8S_&lt;ENVIRONMENT&gt;_CLUSTER_NAME</code></td>
<td style="text-align: center">The cluster name is <code>live-1.cloud-platform.service.justice.gov.uk</code></td>
</tr>
<tr>
<td><code>K8S_&lt;ENVIRONMENT&gt;_NAMESPACE</code></td>
<td style="text-align: center">This variable should be equal to the name of your namespace.</td>
</tr>
<tr>
<td><code>K8S_&lt;ENVIRONMENT&gt;_TOKEN</code></td>
<td style="text-align: center">The token is another attribute found in the <code>default-token</code> secret and needs base64 decoding.</td>
</tr>

        </table>
      </div><p>After triggering the CircleCI pipeline, your application should now deploy into your new environment.</p>
<h3 id="deleting-your-live-0-deployment">Deleting your Live-0 deployment</h3><p>The last thing you will need to do is to delete your application from the <code>live-0</code> cluster.</p>
<p>Please see the documentation on <a href="/archive.html#cleaning-up">cleaning up within the Cloud Platform</a>.</p>
<h3 id="other-considerations">Other considerations</h3>


            
          </main>

            <ul class="contribution-banner">
              <li><a href="https://github.com/ministryofjustice/cloud-platform-user-guide/blob/master/source/archive.html.md.erb">View source</a></li>
              <li><a href="https://github.com/ministryofjustice/cloud-platform-user-guide/issues/new?labels=bug&amp;title=Re:%20'Archive'&amp;body=Problem%20with%20'Archive'%20(https://user-guide.cloud-platform.service.justice.gov.uk/archive.html)">Report problem</a></li>
              <li><a href="https://github.com/ministryofjustice/cloud-platform-user-guide">GitHub Repo</a></li>
            </ul>

          <footer class="footer">
  <div class="footer__licence">
    <a class="footer__licence-logo" href="https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/" rel="license">Open Government Licence</a>
    <p class="footer__licence-description">All content is available under the <a href="https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/" rel="license">Open Government Licence v3.0</a>, except where otherwise stated</p>
  </div>

  <div class="footer__copyright">
    <a class="footer__copyright-logo" href="http://www.nationalarchives.gov.uk/information-management/re-using-public-sector-information/copyright-and-re-use/crown-copyright/">© Crown copyright</a>
  </div>
</footer>

        </div>
      </div>
    </div>

    
  </body>
</html>

<script>
  // Add the current window.location to the body of the
  // feedback email message.
  function sendFeedback(mailto, event) {
    event.preventDefault();

    var body = "Feedback/Problem on page: " + window.location + "\n";
    var href = mailto + '&body=' + encodeURIComponent(body);

    window.location = href;
  }

  $(document).ready(function() {
    var feedbackLink = $('a[href^="mailto:"]:contains("Feedback")')[0];
    var mailto = feedbackLink.href;
    $(feedbackLink).on('click', function(event) { sendFeedback(mailto, event); });
  });
</script>
